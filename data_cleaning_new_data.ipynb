{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Projet Integre</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_cleaning_library.py # on charge toutes les librairies et fonctions qui ont été crées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:/Users/Romain/Desktop/fichiers_projets/publication.csv',delimiter=';',encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication=data[data['categorie']=='article'].sample(500000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "      <th>categorie</th>\n",
       "      <th>nbr_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1126526</th>\n",
       "      <td>journals/nar/NakamuraGI98</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>Codon usage tabulated from the international DNA sequence databases.</td>\n",
       "      <td>article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581201</th>\n",
       "      <td>journals/prl/EvansLCD06</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>View synthesis for depth from motion 3D X-ray imaging.</td>\n",
       "      <td>article</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258934</th>\n",
       "      <td>journals/fttcs/Vadhan12</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>Pseudorandomness.</td>\n",
       "      <td>article</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036919</th>\n",
       "      <td>journals/dm/KatonaQ93</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>The largest component in a random subgraph of the n-cycle.</td>\n",
       "      <td>article</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518454</th>\n",
       "      <td>journals/cor/LabbeLS98</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>Covering a graph with cycles.</td>\n",
       "      <td>article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id_publication    date_pub  \\\n",
       "1126526  journals/nar/NakamuraGI98  2020-05-17   \n",
       "581201     journals/prl/EvansLCD06  2020-02-22   \n",
       "1258934    journals/fttcs/Vadhan12  2020-08-20   \n",
       "2036919      journals/dm/KatonaQ93  2020-02-22   \n",
       "518454      journals/cor/LabbeLS98  2020-02-18   \n",
       "\n",
       "                                                                article_title  \\\n",
       "1126526  Codon usage tabulated from the international DNA sequence databases.   \n",
       "581201                 View synthesis for depth from motion 3D X-ray imaging.   \n",
       "1258934                                                     Pseudorandomness.   \n",
       "2036919            The largest component in a random subgraph of the n-cycle.   \n",
       "518454                                          Covering a graph with cycles.   \n",
       "\n",
       "        categorie nbr_authors  \n",
       "1126526   article           3  \n",
       "581201    article           4  \n",
       "1258934   article           1  \n",
       "2036919   article           2  \n",
       "518454    article           3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication.head() # Aperçu du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication.drop(columns=['categorie','nbr_authors'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_publication, date_pub, article_title]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication[publication.duplicated()] # Doublons sur les lignes ? Non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745429</th>\n",
       "      <td>journals/scientometrics/Bar-Ilan08a</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877909</th>\n",
       "      <td>journals/clsr/Zajac87e</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>US focus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121345</th>\n",
       "      <td>journals/alife/Llarena10</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774677</th>\n",
       "      <td>journals/ejcon/Landau99</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>Editorial.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608745</th>\n",
       "      <td>journals/corr/BessiereRGKNNOP15</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>The Inductive Constraint Programming Loop.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357617</th>\n",
       "      <td>journals/micro/X01f</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>Micro News.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055586</th>\n",
       "      <td>journals/sqj/Harrison18b</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>In this issue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035320</th>\n",
       "      <td>journals/tpds/KleppmannB17</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>A Conflict-Free Replicated JSON Datatype.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688859</th>\n",
       "      <td>journals/ieicet/Nagase18</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>Foreword.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812540</th>\n",
       "      <td>journals/cr/X11z</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>Rechtsprechung zum Telekommunikationsrecht.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id_publication    date_pub  \\\n",
       "1745429  journals/scientometrics/Bar-Ilan08a  2020-07-17   \n",
       "1877909               journals/clsr/Zajac87e  2020-10-13   \n",
       "121345              journals/alife/Llarena10  2020-03-13   \n",
       "774677               journals/ejcon/Landau99  2017-05-28   \n",
       "1608745      journals/corr/BessiereRGKNNOP15  2018-08-13   \n",
       "...                                      ...         ...   \n",
       "357617                   journals/micro/X01f  2015-12-09   \n",
       "2055586             journals/sqj/Harrison18b  2020-06-08   \n",
       "1035320           journals/tpds/KleppmannB17  2020-10-02   \n",
       "688859              journals/ieicet/Nagase18  2020-04-11   \n",
       "1812540                     journals/cr/X11z  2018-07-03   \n",
       "\n",
       "                                       article_title  \n",
       "1745429                                         The   \n",
       "1877909                                    US focus.  \n",
       "121345                                          None  \n",
       "774677                                    Editorial.  \n",
       "1608745   The Inductive Constraint Programming Loop.  \n",
       "...                                              ...  \n",
       "357617                                   Micro News.  \n",
       "2055586                               In this issue.  \n",
       "1035320    A Conflict-Free Replicated JSON Datatype.  \n",
       "688859                                     Foreword.  \n",
       "1812540  Rechtsprechung zum Telekommunikationsrecht.  \n",
       "\n",
       "[9166 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication[publication['article_title'].duplicated(keep=False)] # doublons sur les colonnes ! : plusieurs fois le même nom d'articles\n",
    "\n",
    "# Note : certaines publications de même titre ont des id_publication qui différent et certaines ont des dates différentes \n",
    "# pour un même id_publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_rows = publication[publication['article_title'].duplicated(keep='first')] # suppression des doublons sur les colonnes \n",
    "publication.drop(delete_rows.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492460"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(publication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1651163</th>\n",
       "      <td>journals/corr/abs-1912-10764</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Layerwise Noise Maximisation to Train Low-Energy Deep Neural Networks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638180</th>\n",
       "      <td>journals/corr/abs-1912-12122</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Deep Learning Based Android Malware Detection Framework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544252</th>\n",
       "      <td>journals/corr/abs-1912-07909</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Condition number bounds for IETI-DP methods that are explicit in h and p.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483519</th>\n",
       "      <td>journals/corr/abs-1912-11919</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>A new spectral method based on two classes of hat functions for solving systems of fractional differential equations and an application to respiratory syncytial virus infection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386347</th>\n",
       "      <td>journals/corr/abs-1912-07314</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>On Opacity Verification for Discrete-Event Systems.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id_publication    date_pub  \\\n",
       "1651163  journals/corr/abs-1912-10764  2020-01-03   \n",
       "1638180  journals/corr/abs-1912-12122  2020-01-03   \n",
       "1544252  journals/corr/abs-1912-07909  2020-01-03   \n",
       "1483519  journals/corr/abs-1912-11919  2020-01-03   \n",
       "1386347  journals/corr/abs-1912-07314  2020-01-03   \n",
       "\n",
       "                                                                                                                                                                             article_title  \n",
       "1651163                                                                                                             Layerwise Noise Maximisation to Train Low-Energy Deep Neural Networks.  \n",
       "1638180                                                                                                                           Deep Learning Based Android Malware Detection Framework.  \n",
       "1544252                                                                                                          Condition number bounds for IETI-DP methods that are explicit in h and p.  \n",
       "1483519  A new spectral method based on two classes of hat functions for solving systems of fractional differential equations and an application to respiratory syncytial virus infection.  \n",
       "1386347                                                                                                                                On Opacity Verification for Discrete-Event Systems.  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication.sort_values(by=['date_pub'])[132000:].head() #26 % documents antérieurs à 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">1er nettoyage : suppression des balises et des caractères indésirables</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = publication[\"article_title\"].str.lower() # conversion des articles en minuscle\n",
    "article_titles = article_titles.tolist() # conversion des articles en liste\n",
    "\n",
    "list_id_publication = list(publication['id_publication']) # liste des identifiants\n",
    "\n",
    "article_titles = dict(zip(list_id_publication,article_titles)) # articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"original_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"original_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['effect of manipulated amplitude and frequency of human voice on dominance and persuasiveness in audio conferences.',\n",
       " 'foreword to the special section on the international conference on computer-aided design and computer graphics (cad/graphics) 2019.',\n",
       " 'author-related factors predicting citation counts of conference papers: focusing on computer and information science.',\n",
       " 'proceedings of the international conference on computational mathematics and inverse problems honoring peter monk.',\n",
       " 'international conference on case-based reasoning (iccbr-99).',\n",
       " 'demonstrations track of the 25th international joint conference on artificial intelligence.',\n",
       " 'conference reports.',\n",
       " 'special issue on splc 2004, the 3rd software product line conference, boston, ma, august-september 2004.',\n",
       " 'special issue: innovative decision systems, extended papers from the 12th eann/7th ifip aiai 2011 joint conferences.',\n",
       " 'observations on an openstreetmap mapping party organised as a social event during an open source gis conference.',\n",
       " 'conference report: the seventh empirical studies of programmers workshop.',\n",
       " 'conference report on 2017 ieee international conference on fuzzy systems (fuzz-ieee 2017) [conference reports].',\n",
       " 'a short report from the international ape conference: \"smarter publishing in the new decade\" - 11-12 january 2011, berlin-brandenburg academy of sciences (preceded by the education and training course: \"understanding and being successful in publishing\" on 10 january 2011).',\n",
       " \"attacks to xu-tilborg's conference key distribution scheme.\",\n",
       " 'introduction: special issue on the 25th european conference on information retrieval research.',\n",
       " 'introduction to the special issue on the 41st european solid-state circuits conference (esscirc).',\n",
       " 'the formation of the ieee council on rfid [conference reports].',\n",
       " 'editorial: bileta 2016 conference special issue.',\n",
       " 'tamer özsu speaks out: on journals, conferences, encyclopedias and technology.',\n",
       " 'introduction to the 28th international conference on logic programming special issue',\n",
       " 'conference report on ieee cig 2014 [conference reports].',\n",
       " 'the second european conference on computer audit, control and security.',\n",
       " 'conference proceedings as a source of scientific information: a bibliometric analysis.',\n",
       " 'a deep learning solution for multimedia conference system assisted by cloud computing.',\n",
       " 'from the ahlist 2011 conference program chair.',\n",
       " 'reverse-engineering conference rankings: what does it take to make a reputable conference?',\n",
       " 'book review: information systems design methodologies: a feature analysis. proceedings of the ifip wg 8.1 working conference on feature analysis of information systems design methodologies, york, uk, 5-7 july 1983.',\n",
       " 'guest editorial - selected papers from the 2017 ieee international solid-state circuits conference.',\n",
       " 'guest editorial: tenth international conference on computability, complexity and randomness (ccr 2015).',\n",
       " 'conference contrasts.',\n",
       " 'preface for special issue on the 2013 asian conference on design and digital engineering.',\n",
       " 'conference reports: recap of date 2019 in florence, italy.',\n",
       " 'guest editorial for the 29th international conference on genome informatics (giw 2018).',\n",
       " 'ijcai-03 conference highlights.',\n",
       " '24th \"ieee international conference on vlsi design\" chennai, india, 2-7 january 2011.',\n",
       " 'international conference on vector and parallel computing.',\n",
       " 'ecir 2010: 32nd european conference on information retrieval research.',\n",
       " 'featured conferences.',\n",
       " 'when harm to conference reputation is self-inflicted.',\n",
       " 'upcoming sigweb supported conferences.',\n",
       " 'second international conference elearning-2011 belgrade.',\n",
       " '\"the state of open government\": a panel discussiondepository library council meeting and federal depository library program conference. arlington, virginia (october 19, 2011).',\n",
       " 'report on the 25th european conference on information retrieval research (ecir-03).',\n",
       " 'editorial special issue on the fifth computational visual media conference (cvm 2017).',\n",
       " 'helping conference attendees better understand research presentations.',\n",
       " 'conferences on neural networks and related topics.',\n",
       " 'measurement-device-independent quantum secret sharing and quantum conference based on gaussian cluster state.',\n",
       " 'fourth national computer security conference, windsor, u.k.',\n",
       " 'spectrum management and the 1979 world administrative radio conference.',\n",
       " 'guest editorial for the special section on best papers from the 2011 conference on predictive models in software engineering (promise).']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching = [s for s in article_titles.values() if 'conference' in s] # test de la présence du mot conference\n",
    "matching[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_1(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': 'codon usage tabulated from the international dna sequence databases ',\n",
       " 'journals/prl/EvansLCD06': 'view synthesis for depth from motion 3d x ray imaging ',\n",
       " 'journals/fttcs/Vadhan12': 'pseudorandomness ',\n",
       " 'journals/dm/KatonaQ93': 'the largest component in a random subgraph of the n cycle ',\n",
       " 'journals/cor/LabbeLS98': 'covering a graph with cycles '}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\">Sauvegarde</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"firstclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"firstclean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> 2ème nettoyage : Suppression de la ponctuation, des tirets et des chaines de caractères référencant des dates ou des pays</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_2(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': 'codon usage tabulated from the international dna sequence databases ',\n",
       " 'journals/prl/EvansLCD06': 'view synthesis for depth from motion 3d x ray imaging ',\n",
       " 'journals/fttcs/Vadhan12': 'pseudorandomness ',\n",
       " 'journals/dm/KatonaQ93': 'the largest component in a random subgraph of the n cycle ',\n",
       " 'journals/cor/LabbeLS98': 'covering a graph with cycles '}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"secondclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"secondclean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> 3ème nettoyage :  Suppression des chaines de caractères référencant des dates ou des pays, suppression de certains mots, suppression des espaces en trop.. (voir fonction) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_3(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in article_titles.copy(): # test de la présence dans la chaine de l'unique présence de characteres spéciaux\n",
    "    # car cela peut causer une erreur dans le test de détection de la langue qui va être fait par la suite\n",
    "    if re.match(r'^[_\\W]+$',article_titles[i]):\n",
    "        del article_titles[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict(article_titles, \"all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492196"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching = [s for s in article_titles.values() if '' in s] # test de la présence du mot conference\n",
    "matching[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> Sélection des articles qui sont uniquements en anglais </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_english(article_titles) # Suppresion de plus de 43 000 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = dict(list(article_titles.items())[0:400000]) # on va travailler sur une base de 400 000 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"only_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"only_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Suppression des stop words</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenisation des titres\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "tokenized_titles = defaultdict(set)\n",
    "for k,v in article_titles.items() :\n",
    "    article_titles[k] = tokenizer.tokenize(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'others', 'serious', 'they', 'enough', 'up', \"doesn't\", 'eleven', 'five', \"haven't\", 'might', 'next', 'itself', 'o', 'had', 'various', 'until', 'whereas', \"hasn't\", 'wasn', 'thick', 'doing', 'myself', \"don't\", 'own', 'name', 'isn', 'm', \"you'd\", 'toward', 'needn', 'whereby', 'without', \"aren't\", 'hereupon', 'anything', 'if', \"she's\", 'behind', 'beforehand', 'whether', 'ma', 'twelve', 'y', 'with', 'i', 'mostly', 'km', 'describe', 'take', 'fifteen', 'regarding', 'fire', 'about', 'whereupon', 'anyhow', 'kg', 'couldn', 'therefore', 'forty', 'whoever', 'seems', 'system', 'been', 'shan', 'alone', 'go', 'on', 'whither', 'becomes', 'thereby', 'although', 'computer', 'themselves', 'off', 'shouldn', 'how', \"shouldn't\", \"isn't\", 'nine', 'have', 'into', 'should', 'them', \"needn't\", 're', 'ten', 'latter', 'three', 'part', 'was', 'everywhere', 'down', 'didn', 'he', 'thus', 'already', 'everything', 'too', 'as', \"couldn't\", \"wouldn't\", 'eg', 'moreover', 'did', 'by', 'per', 'also', 'it', 'do', 'most', 'what', 'ie', 'everyone', \"should've\", 'thence', 'were', 'all', 'six', 'full', 'due', 'none', 'before', 'yet', 'for', 'these', 'yourself', 'a', 'anyone', 'same', 'herein', \"that'll\", 'than', 'between', 'somehow', 'whatever', 'mine', 'she', 'sincere', 'detail', 'rather', 'an', 'please', 'whenever', 'along', 'herself', 'hasnt', 'there', 'fill', 'their', 'during', 'beyond', 'amoungst', \"mustn't\", 'd', 'besides', 'seemed', 'move', 'quite', 'any', 'yours', 'via', \"didn't\", 'co', 'hereby', 'very', 'but', 'being', 'we', 'say', 'haven', 'always', 'wouldn', 'ours', 'now', 'or', 'anyway', 'from', 'hadn', 'few', 'below', 'former', 'against', \"you're\", 'bill', 'whose', 'un', 'otherwise', 'noone', 'doesn', 'etc', 'thru', 'last', 'her', 'whence', 'top', 'hers', 'get', 'may', 'so', 'ever', 'many', 'side', 'hence', 'your', 'thereafter', 'another', 'which', 'me', 'afterwards', 'nowhere', 'not', 'elsewhere', 'sixty', 'other', 'the', 'indeed', 'won', 'cannot', 'using', 'unless', 'mightn', 'inc', 'yourselves', 'would', 'him', 'though', 'must', 'upon', 'onto', 'here', 'nevertheless', 'be', 'empty', 'every', 'throughout', 'became', 'made', 'done', 'eight', 'put', \"weren't\", 'cry', 'ourselves', 'even', 'nor', 'interest', 'across', 'either', 'again', 'don', 'much', 'will', 've', 'at', 'thereupon', 'something', 'call', 'keep', 'nothing', 'see', 'wherever', 'meanwhile', 'is', 'its', 'perhaps', 'else', 'no', 'and', 'therein', 'namely', 'within', 'bottom', 'latterly', 'mustn', \"mightn't\", 'can', 'hundred', 'two', 'through', 'll', 'having', 'make', 'both', \"won't\", 'then', 'this', 'you', 'together', 'seem', 'almost', 'less', 'amongst', 'twenty', 'still', 'except', 'de', 'to', 'give', 'that', 'himself', \"hadn't\", 't', 'ltd', 'such', 'hasn', 'only', 'thin', \"it's\", \"you'll\", 'does', 'third', 'formerly', 'find', 'beside', 'mill', 'seeming', 'after', 'one', 'more', 'con', 'around', 'our', 'since', 'those', 'anywhere', \"shan't\", 'us', \"you've\", 'four', 'who', 'least', 'someone', 'towards', 'front', 'neither', 'whole', 'fifty', 'under', 'could', 'cant', 'hereafter', 'whom', 'out', 'found', 'sometime', 'while', 'my', 'some', 'in', \"wasn't\", 'just', 'nobody', 'becoming', 'first', 'theirs', 'am', 'often', 'become', 'used', 's', 'his', 'each', 'whereafter', 'ain', 'show', 'never', 'where', 'when', 'sometimes', 'above', 'why', 'further', 'are', 'somewhere', 'well', 'among', 'weren', 'amount', 'back', 'of', 'once', 'really', 'has', 'aren', 'because', 'over', 'couldnt', 'however', 'several', 'wherein'})\n"
     ]
    }
   ],
   "source": [
    "# suppression des mots vides\n",
    "\n",
    "stopwords = set()\n",
    "stopwords.update(tuple(nltk.corpus.stopwords.words('english')))\n",
    "all_stopwords = STOPWORDS.union(stopwords)\n",
    "print(all_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in article_titles.items() :\n",
    "    article_titles[k] = [word for word in v if word not in all_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"nostopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"nostopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': ['codon',\n",
       "  'usage',\n",
       "  'tabulated',\n",
       "  'dna',\n",
       "  'sequence',\n",
       "  'databases'],\n",
       " 'journals/prl/EvansLCD06': ['view',\n",
       "  'synthesis',\n",
       "  'depth',\n",
       "  'motion',\n",
       "  '3d',\n",
       "  'ray',\n",
       "  'imaging'],\n",
       " 'journals/dm/KatonaQ93': ['largest',\n",
       "  'component',\n",
       "  'random',\n",
       "  'subgraph',\n",
       "  'cycle'],\n",
       " 'journals/cor/LabbeLS98': ['covering', 'graph', 'cycles'],\n",
       " 'journals/ita/GaibissoGT90': ['partially',\n",
       "  'persistent',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'set',\n",
       "  'union',\n",
       "  'problem']}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatisation(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': ['codon',\n",
       "  'usage',\n",
       "  'tabulate',\n",
       "  'dna',\n",
       "  'sequence',\n",
       "  'database'],\n",
       " 'journals/prl/EvansLCD06': ['view',\n",
       "  'synthesis',\n",
       "  'depth',\n",
       "  'motion',\n",
       "  '3d',\n",
       "  'ray',\n",
       "  'image'],\n",
       " 'journals/dm/KatonaQ93': ['large',\n",
       "  'component',\n",
       "  'random',\n",
       "  'subgraph',\n",
       "  'cycle'],\n",
       " 'journals/cor/LabbeLS98': ['cover', 'graph', 'cycle'],\n",
       " 'journals/ita/GaibissoGT90': ['partially',\n",
       "  'persistent',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'set',\n",
       "  'union',\n",
       "  'problem']}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaireart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching = [s for s in article_titles.values() if 'cycle' in s] # test de la présence du mot conference\n",
    "len(matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"lemmatized_without_based\") # suite à la visualisation des données du notebook visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (<ipython-input-12-4bd5a1ec1992>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-4bd5a1ec1992>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    dict(list(len(article_titles.items()))<3)[0:5]) # affichage des 5 premiers éléments du dictionnaireart\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "len(article_titles.items()<3)[0:5] # affichage des 5 premiers éléments du dictionnaireart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaireart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des articles qui font moins de 3 mots\n",
    "nb=0\n",
    "for key, val in article_titles.copy().items():\n",
    "    if (len(article_titles[key])<3):\n",
    "        del(article_titles[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394039"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"lemmatized_more_than_2_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_token_dict=load_dict('lemmatized_more_than_2_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=list(article_titles_token_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394039"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_str_lst = []\n",
    "lst = list(article_titles_token_dict.values())\n",
    "\n",
    "for i in lst:\n",
    "    a=\" \".join([k for k in i])\n",
    "    article_titles_str.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles_str, \"article_titles_str_lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_str=load_dict(\"article_titles_str_lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codon usage tabulate dna sequence database',\n",
       " 'view synthesis depth motion 3d ray image',\n",
       " 'large component random subgraph cycle',\n",
       " 'cover graph cycle',\n",
       " 'partially persistent data structure set union problem']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles_str[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_token_dict = load_dict(\"article_title_token_dict\") # = lemmatized_more_than_2_words (après duplication et renommage du pickle)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_str_lst = load_dict(\"article_titles_str_lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': ['codon',\n",
       "  'usage',\n",
       "  'tabulate',\n",
       "  'dna',\n",
       "  'sequence',\n",
       "  'database'],\n",
       " 'journals/prl/EvansLCD06': ['view',\n",
       "  'synthesis',\n",
       "  'depth',\n",
       "  'motion',\n",
       "  '3d',\n",
       "  'ray',\n",
       "  'image'],\n",
       " 'journals/dm/KatonaQ93': ['large',\n",
       "  'component',\n",
       "  'random',\n",
       "  'subgraph',\n",
       "  'cycle'],\n",
       " 'journals/cor/LabbeLS98': ['cover', 'graph', 'cycle'],\n",
       " 'journals/ita/GaibissoGT90': ['partially',\n",
       "  'persistent',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'set',\n",
       "  'union',\n",
       "  'problem']}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles_token_dict.items())[0:5]) # affichage des 5 premiers éléments du dictionnaireart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codon usage tabulate dna sequence database',\n",
       " 'view synthesis depth motion 3d ray image',\n",
       " 'large component random subgraph cycle',\n",
       " 'cover graph cycle',\n",
       " 'partially persistent data structure set union problem']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles_str_lst[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
